"""
è¦‹ç©æ›¸ä½œæˆ

ä»•æ§˜æ›¸PDFã‹ã‚‰è¦‹ç©æ›¸ã‚’è‡ªå‹•ç”Ÿæˆã™ã‚‹AIã‚·ã‚¹ãƒ†ãƒ 
"""

import streamlit as st
from pathlib import Path
import tempfile
import json
from datetime import datetime
from loguru import logger
import sys
import zipfile
from io import BytesIO
import time

sys.path.insert(0, '.')

from pipelines.logging_config import setup_logging
setup_logging()

from pipelines.schemas import DisciplineType
from pipelines.estimate_generator_with_legal import EstimateGeneratorWithLegal
from pipelines.estimate_validator import EstimateValidator
from pipelines.estimate_from_reference import EstimateFromReference
from pipelines.estimate_generator_ai import AIEstimateGenerator
from pipelines.export import EstimateExporter
from pipelines.cost_tracker import start_session, end_session, get_tracker


# ã‚«ã‚¹ã‚¿ãƒ CSSï¼ˆãƒšãƒ¼ã‚¸å›ºæœ‰ï¼‰
st.markdown("""
<style>
    /* ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã‚«ãƒ¼ãƒ‰ */
    [data-testid="stMetricValue"] {
        font-size: 1.4rem;
        font-weight: 600;
    }
    [data-testid="stMetricLabel"] {
        font-size: 0.85rem;
    }
    /* ã‚¿ãƒ–ã‚¹ã‚¿ã‚¤ãƒ« */
    .stTabs [data-baseweb="tab"] {
        padding: 12px 24px;
        font-weight: 500;
        font-size: 0.95rem;
    }
    /* ã‚»ã‚¯ã‚·ãƒ§ãƒ³ãƒ˜ãƒƒãƒ€ãƒ¼ */
    .sidebar-section-header {
        font-size: 0.9rem;
        font-weight: 600;
        margin-bottom: 0.5rem;
        padding-bottom: 0.3rem;
        border-bottom: 1px solid rgba(128, 128, 128, 0.2);
    }
</style>
""", unsafe_allow_html=True)


def init_session_state():
    """ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹ã‚’åˆæœŸåŒ–"""
    defaults = {
        'fmt_doc': None,
        'validation_results': None,
        'processing_time': None,
        'legal_refs': [],
        'generated_files': [],
        'email_info': None,
        'is_processing': False,
    }
    for key, value in defaults.items():
        if key not in st.session_state:
            st.session_state[key] = value


def extract_email_info_auto(uploaded_email):
    """ãƒ¡ãƒ¼ãƒ«æƒ…å ±ã‚’è‡ªå‹•æŠ½å‡º"""
    from pipelines.email_extractor import EmailExtractor

    with tempfile.NamedTemporaryFile(delete=False, suffix=".pdf") as tmp_email:
        tmp_email.write(uploaded_email.read())
        tmp_email_path = tmp_email.name

    extractor = EmailExtractor()
    email_info = extractor.extract_email_info(tmp_email_path)
    return email_info


def main():
    init_session_state()

    # ãƒ˜ãƒƒãƒ€ãƒ¼
    st.title("è¦‹ç©æ›¸ä½œæˆ")
    st.caption("ä»•æ§˜æ›¸PDFã‹ã‚‰è¦‹ç©æ›¸ã‚’è‡ªå‹•ç”Ÿæˆ")

    # ã‚µã‚¤ãƒ‰ãƒãƒ¼
    with st.sidebar:
        # å˜ä¾¡DBçŠ¶æ…‹
        st.markdown('<p class="sidebar-section-header">å˜ä¾¡ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹</p>', unsafe_allow_html=True)
        try:
            with open('kb/price_kb.json', 'r') as f:
                kb_data = json.load(f)
            kb_count = len(kb_data)
            st.caption(f"ç™»éŒ²é …ç›®: {kb_count:,}ä»¶")
        except:
            st.caption("æœªæ§‹ç¯‰")

        st.markdown("---")

        # æ³•ä»¤è¨­å®š
        st.markdown('<p class="sidebar-section-header">æ³•ä»¤å‚ç…§è¨­å®š</p>', unsafe_allow_html=True)
        include_legal = st.checkbox("æ³•ä»¤æƒ…å ±ã‚’å«ã‚ã‚‹", value=True)
        if include_legal:
            legal_standards = st.multiselect(
                "å‚ç…§æ³•ä»¤",
                ["å»ºç¯‰åŸºæº–æ³•", "é›»æ°—è¨­å‚™æŠ€è¡“åŸºæº–", "ã‚¬ã‚¹äº‹æ¥­æ³•", "æ¶ˆé˜²æ³•", "JEAC8001"],
                default=["å»ºç¯‰åŸºæº–æ³•", "é›»æ°—è¨­å‚™æŠ€è¡“åŸºæº–", "ã‚¬ã‚¹äº‹æ¥­æ³•", "æ¶ˆé˜²æ³•", "JEAC8001"],
                label_visibility="collapsed"
            )
        else:
            legal_standards = []

        st.markdown("---")

        # å‡¦ç†çŠ¶æ³
        if st.session_state.is_processing:
            st.info("å‡¦ç†ä¸­...")
        elif st.session_state.fmt_doc:
            st.success("ç”Ÿæˆå®Œäº†")

    # ã‚¿ãƒ–ã§æ©Ÿèƒ½ã‚’åˆ†å‰²
    tab1, tab2, tab3 = st.tabs(["ä»•æ§˜æ›¸ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰", "ç”Ÿæˆçµæœ", "ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰"])

    # ===== ã‚¿ãƒ–1: ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ =====
    with tab1:
        # ä»•æ§˜æ›¸ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã‚»ã‚¯ã‚·ãƒ§ãƒ³
        st.markdown("**ä»•æ§˜æ›¸PDF**")
        uploaded_files = st.file_uploader(
            "ä»•æ§˜æ›¸PDF",
            type=['pdf'],
            accept_multiple_files=True,
            label_visibility="collapsed",
            key="spec_upload",
            help="è¤‡æ•°ãƒ•ã‚¡ã‚¤ãƒ«ã®ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ãŒå¯èƒ½ã§ã™"
        )

        # ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰æ¸ˆã¿ãƒ•ã‚¡ã‚¤ãƒ«è¡¨ç¤º
        if uploaded_files:
            file_names = ", ".join([f.name for f in uploaded_files])
            st.caption(f"ğŸ“„ {len(uploaded_files)}ãƒ•ã‚¡ã‚¤ãƒ«é¸æŠæ¸ˆã¿: {file_names}")

        st.divider()

        # ãƒ¡ãƒ¼ãƒ«æƒ…å ±ã‚»ã‚¯ã‚·ãƒ§ãƒ³ï¼ˆæŠ˜ã‚ŠãŸãŸã¿ï¼‰
        with st.expander("ãƒ¡ãƒ¼ãƒ«æœ¬æ–‡ã‹ã‚‰æƒ…å ±ã‚’æŠ½å‡ºï¼ˆä»»æ„ï¼‰", expanded=False):
            uploaded_email = st.file_uploader(
                "ãƒ¡ãƒ¼ãƒ«æœ¬æ–‡PDF",
                type=['pdf'],
                help="é¡§å®¢åãƒ»å·¥æœŸã‚’è‡ªå‹•æŠ½å‡º",
                label_visibility="collapsed",
                key="email_upload"
            )

            # ãƒ¡ãƒ¼ãƒ«PDFãŒã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã•ã‚ŒãŸã‚‰è‡ªå‹•ã§è§£æ
            if uploaded_email and st.session_state.email_info is None:
                with st.spinner("è§£æä¸­..."):
                    try:
                        email_info = extract_email_info_auto(uploaded_email)
                        st.session_state.email_info = email_info
                        st.rerun()
                    except Exception as e:
                        st.error(f"è§£æã‚¨ãƒ©ãƒ¼: {e}")

            # ãƒ¡ãƒ¼ãƒ«æƒ…å ±è¡¨ç¤º
            if st.session_state.email_info:
                email = st.session_state.email_info
                st.success("ãƒ¡ãƒ¼ãƒ«æƒ…å ±ã‚’æŠ½å‡ºã—ã¾ã—ãŸ")

                col1, col2 = st.columns(2)
                with col1:
                    st.text(f"é¡§å®¢: {email.client_company or '-'} {email.client_branch or ''}")
                    st.text(f"æ‹…å½“: {email.client_contact or '-'}")
                    st.text(f"æœŸé™: {email.quote_deadline or '-'}")

                with col2:
                    st.text(f"å·¥æœŸ: {email.construction_start or '-'} ï½ {email.construction_end or '-'}")
                    st.text(f"ãƒ¬ãƒ³ã‚¿ãƒ«: {email.rental_start or '-'} ï½ {email.rental_end or '-'}")
                    st.text(f"é¢ç©: {email.building_area_tsubo or '-'}åª")

                if st.button("ã‚¯ãƒªã‚¢", type="secondary", key="clear_email"):
                    st.session_state.email_info = None
                    st.rerun()

        st.divider()

        # ç”Ÿæˆãƒœã‚¿ãƒ³
        col1, col2, col3 = st.columns([1, 1, 1])
        with col2:
            if uploaded_files:
                if st.button("è¦‹ç©æ›¸ã‚’ç”Ÿæˆ", type="primary", disabled=st.session_state.is_processing, use_container_width=True):
                    generate_estimate_unified(
                        uploaded_files,
                        include_legal,
                        legal_standards
                    )
            else:
                st.button("è¦‹ç©æ›¸ã‚’ç”Ÿæˆ", type="primary", disabled=True, use_container_width=True)
                st.caption("ä»•æ§˜æ›¸ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„")

    # ===== ã‚¿ãƒ–2: ç”Ÿæˆçµæœ =====
    with tab2:
        if st.session_state.fmt_doc and st.session_state.generated_files:
            fmt_doc = st.session_state.fmt_doc
            items = fmt_doc.estimates if hasattr(fmt_doc, 'estimates') else fmt_doc.estimate_items
            total_items = len(items)
            with_price = sum(1 for item in items if item.unit_price and item.unit_price > 0)
            # Level 0ï¼ˆå·¥äº‹åŒºåˆ†ã®è¦ªé …ç›®ï¼‰ã®åˆè¨ˆã®ã¿ã‚’ä½¿ç”¨ï¼ˆPDFã¨ä¸€è‡´ã•ã›ã‚‹ï¼‰
            total_amount = sum(item.amount or 0 for item in items if item.level == 0)

            # ãƒ¡ãƒˆãƒªã‚¯ã‚¹ï¼ˆ3ã‚«ãƒ©ãƒ ã«å¤‰æ›´ï¼‰
            col1, col2, col3 = st.columns(3)
            with col1:
                st.metric("ç”Ÿæˆé …ç›®æ•°", f"{total_items}ä»¶")
            with col2:
                rate = with_price/total_items*100 if total_items > 0 else 0
                st.metric("å˜ä¾¡ãƒãƒƒãƒãƒ³ã‚°ç‡", f"{rate:.0f}%", f"{with_price}/{total_items}ä»¶")
            with col3:
                st.metric("æ¨å®šç·é¡", f"Â¥{total_amount:,.0f}")

            st.divider()

            # å·¥äº‹åŒºåˆ†åˆ¥å†…è¨³
            st.markdown("**å·¥äº‹åŒºåˆ†åˆ¥å†…è¨³**")

            disc_stats = {}
            for item in items:
                disc = item.discipline.value if item.discipline else "ãã®ä»–"
                if disc not in disc_stats:
                    disc_stats[disc] = {'count': 0, 'amount': 0}
                disc_stats[disc]['count'] += 1
                # Level 0ï¼ˆå·¥äº‹åŒºåˆ†ã®è¦ªé …ç›®ï¼‰ã®é‡‘é¡ã®ã¿ã‚’åˆè¨ˆï¼ˆé‡è¤‡è¨ˆç®—ã‚’é˜²æ­¢ï¼‰
                # Level 1ä»¥ä¸Šã¯è¦ªé …ç›®ã®é‡‘é¡ã«å«ã¾ã‚Œã¦ã„ã‚‹ãŸã‚åŠ ç®—ã—ãªã„
                if item.level == 0:
                    disc_stats[disc]['amount'] += item.amount or 0

            # æ¨ªä¸¦ã³ã§è¡¨ç¤º
            cols = st.columns(len(disc_stats)) if disc_stats else []
            for col, (disc, stats) in zip(cols, sorted(disc_stats.items())):
                with col:
                    st.metric(disc, f"Â¥{stats['amount']:,.0f}", f"{stats['count']}é …ç›®")

            st.divider()

            # é …ç›®ä¸€è¦§
            st.markdown("**ç”Ÿæˆé …ç›®ä¸€è¦§**")

            # ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ ç”¨ã«ãƒ‡ãƒ¼ã‚¿æ•´å½¢
            display_data = []
            for item in items[:100]:  # æœ€å¤§100ä»¶è¡¨ç¤º
                # éšå±¤ã«å¿œã˜ãŸã‚¤ãƒ³ãƒ‡ãƒ³ãƒˆ
                indent = "ã€€" * item.level
                display_data.append({
                    "No.": item.item_no if item.item_no else "",
                    "é …ç›®å": f"{indent}{item.name}",
                    "ä»•æ§˜": item.specification or "",
                    "æ•°é‡": item.quantity if item.quantity else "",
                    "å˜ä½": item.unit or "",
                    "å˜ä¾¡": f"Â¥{item.unit_price:,.0f}" if item.unit_price else "",
                    "é‡‘é¡": f"Â¥{item.amount:,.0f}" if item.amount else "",
                })

            st.dataframe(display_data, use_container_width=True, hide_index=True, height=400)

            if len(items) > 100:
                st.caption(f"â€» å…¨{len(items)}ä»¶ä¸­ã€100ä»¶ã‚’è¡¨ç¤º")

            # å‡¦ç†æ™‚é–“
            if st.session_state.processing_time:
                st.caption(f"å‡¦ç†æ™‚é–“: {st.session_state.processing_time:.1f}ç§’")

            # æ•´åˆæ€§ãƒã‚§ãƒƒã‚¯
            st.divider()
            st.markdown("**æ•´åˆæ€§ãƒã‚§ãƒƒã‚¯**")
            try:
                from pipelines.estimate_validator import EstimateValidator
                validator = EstimateValidator()
                validation_results = validator.validate_estimate(fmt_doc)

                # ã‚µãƒãƒªãƒ¼è¡¨ç¤º
                summary = validation_results.get("summary", {})
                col1, col2 = st.columns(2)
                with col1:
                    st.metric("å˜ä¾¡/ã¡", f"Â¥{summary.get('amount_per_sqm', 0):,.0f}")
                with col2:
                    status = "âœ“ å¦¥å½“" if validation_results.get("is_valid") else "âš  è¦ç¢ºèª"
                    st.metric("åˆ¤å®š", status)

                # å·¥äº‹åŒºåˆ†åˆ¥ãƒã‚§ãƒƒã‚¯
                with st.expander("å·¥äº‹åŒºåˆ†åˆ¥ãƒã‚§ãƒƒã‚¯çµæœ", expanded=False):
                    for disc_name, check in validation_results.get("discipline_checks", {}).items():
                        if check["status"] == "ok":
                            st.success(check["message"])
                        elif check["status"] == "warning":
                            st.warning(check["message"])
                        else:
                            st.error(check["message"])

                # ç•°å¸¸é …ç›®
                anomalies = validation_results.get("anomaly_items", [])
                if anomalies:
                    with st.expander(f"âš  ç•°å¸¸é …ç›® ({len(anomalies)}ä»¶)", expanded=True):
                        for anomaly in anomalies:
                            st.warning(f"{anomaly['item']}: {anomaly['message']}")

            except Exception as e:
                st.warning(f"æ•´åˆæ€§ãƒã‚§ãƒƒã‚¯ã‚¨ãƒ©ãƒ¼: {e}")

            # ãƒã‚§ãƒƒã‚¯ãƒªã‚¹ãƒˆç¶²ç¾…æ€§
            st.divider()
            st.markdown("**ãƒã‚§ãƒƒã‚¯ãƒªã‚¹ãƒˆç¶²ç¾…æ€§**")
            checklist_coverage = fmt_doc.metadata.get("checklist_coverage", {})
            if checklist_coverage:
                if isinstance(checklist_coverage, dict):
                    # è¤‡æ•°å·¥äº‹åŒºåˆ†ã®å ´åˆ
                    if "coverage_rate" in checklist_coverage:
                        # å˜ä¸€å·¥äº‹åŒºåˆ†
                        rate = checklist_coverage.get("coverage_rate", 0) * 100
                        covered = checklist_coverage.get("covered_count", 0)
                        total = checklist_coverage.get("total_check_items", 0)
                        st.metric("ã‚«ãƒãƒ¼ç‡", f"{rate:.0f}%", f"{covered}/{total}é …ç›®")
                        missing = checklist_coverage.get("missing_items", [])
                        if missing:
                            with st.expander(f"ä¸è¶³é …ç›® ({len(missing)}ä»¶)", expanded=False):
                                for item in missing[:20]:
                                    st.caption(f"ãƒ»{item}")
                    else:
                        # è¤‡æ•°å·¥äº‹åŒºåˆ†
                        cols = st.columns(len(checklist_coverage))
                        for col, (disc, cov) in zip(cols, checklist_coverage.items()):
                            with col:
                                rate = cov.get("coverage_rate", 0) * 100
                                st.metric(disc, f"{rate:.0f}%")

            # ã¡å˜ä¾¡æ¤œè¨¼
            unit_price_checks = fmt_doc.metadata.get("unit_price_checks", {}) or fmt_doc.metadata.get("unit_price_check", {})
            if unit_price_checks:
                st.divider()
                st.markdown("**ã¡å˜ä¾¡æ¤œè¨¼**")
                if "is_valid" in unit_price_checks:
                    # å˜ä¸€
                    msg = unit_price_checks.get("message", "")
                    if unit_price_checks.get("is_valid"):
                        st.success(msg)
                    else:
                        st.warning(msg)
                else:
                    # è¤‡æ•°å·¥äº‹åŒºåˆ†
                    for disc, check in unit_price_checks.items():
                        msg = check.get("message", "")
                        if check.get("is_valid"):
                            st.success(f"{disc}: {msg}")
                        else:
                            st.warning(f"{disc}: {msg}")

        else:
            st.info("è¦‹ç©æ›¸ã‚’ç”Ÿæˆã™ã‚‹ã¨ã€ã“ã“ã«çµæœãŒè¡¨ç¤ºã•ã‚Œã¾ã™ã€‚")

    # ===== ã‚¿ãƒ–3: ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ =====
    with tab3:
        if st.session_state.generated_files:
            all_files = st.session_state.generated_files

            # ZIPä¸€æ‹¬ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰
            zip_buffer = BytesIO()
            with zipfile.ZipFile(zip_buffer, 'w', zipfile.ZIP_DEFLATED) as zf:
                for file_info in all_files:
                    spec_name = file_info['spec_name']

                    # JSON
                    if file_info.get('fmt_json') and Path(file_info['fmt_json']).exists():
                        zf.write(file_info['fmt_json'], f"{spec_name}/{Path(file_info['fmt_json']).name}")

                    # PDF
                    for pdf_path in file_info.get('pdfs', []):
                        if Path(pdf_path).exists():
                            zf.write(pdf_path, f"{spec_name}/{Path(pdf_path).name}")

                    # Summary
                    if file_info.get('summary') and Path(file_info['summary']).exists():
                        zf.write(file_info['summary'], f"{spec_name}/{Path(file_info['summary']).name}")

            zip_buffer.seek(0)
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")

            total_file_count = sum(
                1 + len(f.get('pdfs', [])) + (1 if f.get('summary') else 0)
                for f in all_files
            )

            col1, col2, col3 = st.columns([1, 1, 1])
            with col2:
                st.download_button(
                    f"å…¨ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ZIPã§ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ï¼ˆ{total_file_count}ä»¶ï¼‰",
                    data=zip_buffer,
                    file_name=f"è¦‹ç©æ›¸_{timestamp}.zip",
                    mime="application/zip",
                    type="primary",
                    use_container_width=True
                )

            st.divider()

            # å€‹åˆ¥ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰
            st.markdown("**å€‹åˆ¥ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰**")

            for file_info in all_files:
                st.markdown(f"**{file_info['spec_name']}**")
                col1, col2, col3 = st.columns(3)

                with col1:
                    if file_info.get('fmt_json') and Path(file_info['fmt_json']).exists():
                        with open(file_info['fmt_json'], 'rb') as f:
                            st.download_button(
                                "JSONãƒ‡ãƒ¼ã‚¿",
                                data=f,
                                file_name=Path(file_info['fmt_json']).name,
                                mime="application/json",
                                use_container_width=True,
                                key=f"json_{file_info['spec_name']}"
                            )

                with col2:
                    for i, pdf_path in enumerate(file_info.get('pdfs', [])):
                        if Path(pdf_path).exists():
                            with open(pdf_path, 'rb') as f:
                                st.download_button(
                                    "è¦‹ç©æ›¸PDF",
                                    data=f,
                                    file_name=Path(pdf_path).name,
                                    mime="application/pdf",
                                    use_container_width=True,
                                    key=f"pdf_{file_info['spec_name']}_{i}"
                                )

                with col3:
                    if file_info.get('summary') and Path(file_info['summary']).exists():
                        with open(file_info['summary'], 'rb') as f:
                            st.download_button(
                                "ã‚µãƒãƒªãƒ¼",
                                data=f,
                                file_name=Path(file_info['summary']).name,
                                mime="text/plain",
                                use_container_width=True,
                                key=f"summary_{file_info['spec_name']}"
                            )

                if file_info != all_files[-1]:
                    st.divider()

        else:
            st.info("è¦‹ç©æ›¸ã‚’ç”Ÿæˆã™ã‚‹ã¨ã€ã“ã“ã‹ã‚‰ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã§ãã¾ã™ã€‚")


def generate_estimate_unified(
    uploaded_files: list,
    include_legal: bool,
    legal_standards: list
):
    """çµ±åˆè¦‹ç©ç”Ÿæˆ"""

    st.session_state.is_processing = True
    st.session_state.generated_files = []
    start_time = datetime.now()

    # ã‚³ã‚¹ãƒˆè¿½è·¡
    session_id = start_session("è¦‹ç©ä½œæˆï¼ˆAIçµ±åˆç”Ÿæˆï¼‰")

    # é€²æ—è¡¨ç¤ºç”¨ã‚³ãƒ³ãƒ†ãƒŠ
    progress_container = st.empty()
    status_container = st.empty()
    detail_container = st.empty()

    try:
        total_files = len(uploaded_files)

        for file_idx, uploaded_file in enumerate(uploaded_files):
            # é€²æ—æ›´æ–°
            progress = (file_idx) / total_files
            progress_container.progress(progress, text=f"å‡¦ç†ä¸­: {file_idx + 1}/{total_files}")
            status_container.info(f"ãƒ•ã‚¡ã‚¤ãƒ«: {uploaded_file.name}")

            # ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«ä¿å­˜
            with tempfile.NamedTemporaryFile(delete=False, suffix='.pdf') as tmp_file:
                tmp_file.write(uploaded_file.read())
                tmp_path = tmp_file.name

            # ã‚¹ãƒ†ãƒƒãƒ—è¡¨ç¤º
            steps = [
                "ä»•æ§˜æ›¸ã‚’è§£æä¸­...",
                "å»ºç‰©æƒ…å ±ã‚’æŠ½å‡ºä¸­...",
                "è¨­å‚™é …ç›®ã‚’ç”Ÿæˆä¸­...",
                "å˜ä¾¡ã‚’ãƒãƒƒãƒãƒ³ã‚°ä¸­...",
                "PDFç”Ÿæˆä¸­..."
            ]

            # AIç”Ÿæˆ
            detail_container.caption(steps[0])

            ai_generator = AIEstimateGenerator(kb_path="kb/price_kb.json")

            detail_container.caption(steps[1])
            time.sleep(0.2)

            detail_container.caption(steps[2])
            fmt_doc = ai_generator.generate_estimate_unified(
                tmp_path,
                legal_standards=legal_standards if include_legal else []
            )

            detail_container.caption(steps[3])

            # ãƒ¡ãƒ¼ãƒ«æƒ…å ±çµ±åˆ
            if st.session_state.email_info:
                email_info = st.session_state.email_info

                if email_info.client_company:
                    fmt_doc.project_info.client_name = f"{email_info.client_company}"
                    if email_info.client_branch:
                        fmt_doc.project_info.client_name += f" {email_info.client_branch}"

                if email_info.construction_start and email_info.construction_end:
                    fmt_doc.project_info.contract_period = f"å·¥æœŸ: {email_info.construction_start} ï½ {email_info.construction_end}"

                if email_info.rental_start and email_info.rental_end:
                    rental_info = f"ãƒ¬ãƒ³ã‚¿ãƒ«æœŸé–“: {email_info.rental_start} ï½ {email_info.rental_end}"
                    if email_info.rental_months:
                        rental_info += f" ({email_info.rental_months}ãƒ¶æœˆ)"
                    if fmt_doc.project_info.contract_period:
                        fmt_doc.project_info.contract_period += f" / {rental_info}"
                    else:
                        fmt_doc.project_info.contract_period = rental_info

                if email_info.quote_deadline:
                    if fmt_doc.project_info.remarks:
                        fmt_doc.project_info.remarks += f"\nè¦‹ç©æå‡ºæœŸé™: {email_info.quote_deadline}"
                    else:
                        fmt_doc.project_info.remarks = f"è¦‹ç©æå‡ºæœŸé™: {email_info.quote_deadline}"

            # å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«ç”Ÿæˆ
            detail_container.caption(steps[4])

            output_dir = Path("output")
            output_dir.mkdir(exist_ok=True)
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            spec_name = Path(uploaded_file.name).stem

            # JSONä¿å­˜
            fmt_json_path = output_dir / f"è¦‹ç©ãƒ‡ãƒ¼ã‚¿_{spec_name}_{timestamp}.json"
            with open(fmt_json_path, 'w', encoding='utf-8') as f:
                json.dump(fmt_doc.model_dump(mode='json'), f, ensure_ascii=False, indent=2)

            # PDFç”Ÿæˆ
            exporter = EstimateExporter(output_dir=str(output_dir))
            pdf_filename = f"è¦‹ç©æ›¸_{spec_name}_{timestamp}.pdf"
            pdf_path = exporter.export_to_pdf(fmt_doc, pdf_filename)

            # ã‚µãƒãƒªãƒ¼ç”Ÿæˆ
            items = fmt_doc.estimates if hasattr(fmt_doc, 'estimates') else fmt_doc.estimate_items
            total_items = len(items)
            with_price = sum(1 for item in items if item.unit_price and item.unit_price > 0)
            # Level 0ï¼ˆå·¥äº‹åŒºåˆ†ã®è¦ªé …ç›®ï¼‰ã®åˆè¨ˆã®ã¿ã‚’ä½¿ç”¨ï¼ˆPDFã¨ä¸€è‡´ã•ã›ã‚‹ï¼‰
            total_amount = sum(item.amount or 0 for item in items if item.level == 0)

            summary_path = output_dir / f"ã‚µãƒãƒªãƒ¼_{spec_name}_{timestamp}.txt"
            with open(summary_path, 'w', encoding='utf-8') as f:
                f.write(f"è¦‹ç©ç”Ÿæˆã‚µãƒãƒªãƒ¼\n")
                f.write(f"=" * 50 + "\n\n")
                f.write(f"ä»•æ§˜æ›¸: {uploaded_file.name}\n")
                f.write(f"ç”Ÿæˆæ—¥æ™‚: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n\n")
                f.write(f"ç”Ÿæˆé …ç›®æ•°: {total_items}ä»¶\n")
                f.write(f"å˜ä¾¡ä»˜ä¸æ•°: {with_price}ä»¶\n")
                f.write(f"ãƒãƒƒãƒãƒ³ã‚°ç‡: {with_price/total_items*100:.1f}%\n" if total_items > 0 else "")
                f.write(f"æ¨å®šç·é¡: Â¥{total_amount:,.0f}\n")

            # çµæœä¿å­˜
            st.session_state.generated_files.append({
                'spec_name': spec_name,
                'fmt_json': fmt_json_path,
                'pdfs': [pdf_path] if pdf_path else [],
                'summary': summary_path,
            })

            st.session_state.fmt_doc = fmt_doc

        # å®Œäº†
        progress_container.progress(1.0, text="å®Œäº†")
        status_container.success("è¦‹ç©æ›¸ã®ç”ŸæˆãŒå®Œäº†ã—ã¾ã—ãŸ")
        detail_container.empty()

        elapsed = (datetime.now() - start_time).total_seconds()
        st.session_state.processing_time = elapsed

        # ã‚³ã‚¹ãƒˆè¿½è·¡çµ‚äº†
        session_cost = end_session()
        if session_cost and session_cost.get("total_cost_jpy", 0) > 0:
            st.info(f"APIæ–™é‡‘: Â¥{session_cost['total_cost_jpy']:.2f}")

    except Exception as e:
        logger.error(f"Generation error: {e}")
        status_container.error(f"ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
        detail_container.empty()
        import traceback
        traceback.print_exc()

    finally:
        st.session_state.is_processing = False
        st.rerun()


if __name__ == "__main__":
    main()
else:
    main()
